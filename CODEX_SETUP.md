# Codex Environment Setup Guide

## ğŸ¯ Quick Start

### One-Line Setup in Codex:

1. **Go to Codex â†’ Setup Script â†’ Manual**
2. **Paste this command:**

```bash
curl -fsSL https://raw.githubusercontent.com/EcomTree/runpod-comfyui-cloud/main/scripts/setup.sh | bash
```

That's it! âœ¨

---

## ğŸ“¦ What Gets Installed?

The setup script automatically installs and configures:

### ComfyUI Environment:
- âœ… ComfyUI from official repository
- âœ… ComfyUI Manager for custom nodes
- âœ… Model directory structure
- âœ… Essential AI models (checkpoints, VAE, LoRAs, etc.)

### Python Packages:
- âœ… PyTorch with CUDA 12.8+ support
- âœ… torchvision, torchaudio
- âœ… xformers (memory-efficient attention)
- âœ… All ComfyUI dependencies

### System Tools:
- âœ… wget, curl, git
- âœ… ffmpeg (video processing)
- âœ… libgl1 (OpenGL support)

### Services:
- âœ… ComfyUI Web UI (Port 8188)
- âœ… Jupyter Lab (Port 8888, no auth)

---

## ğŸ”§ Environment Variables (Optional)

Set these in Codex UI before starting:

| Variable | Default | Description |
|----------|---------|-------------|
| `DOWNLOAD_MODELS` | `true` | Auto-download AI models |
| `HF_TOKEN` | - | Hugging Face token (for gated models) |
| `COMFYUI_PORT` | `8188` | ComfyUI web interface port |
| `JUPYTER_PORT` | `8888` | Jupyter Lab port |

---

## ğŸ§ª Testing After Setup

```bash
# Check ComfyUI
curl http://localhost:8188/queue

# Check Jupyter Lab
curl http://localhost:8888/

# List installed models
find /workspace/ComfyUI/models -name "*.safetensors" | wc -l

# View logs
tail -f /workspace/comfyui.log
```

---

## ğŸ¨ Using ComfyUI in Codex

1. **Access Web UI:**
   - ComfyUI: `https://your-codex-url:8188`
   - Jupyter: `https://your-codex-url:8888`

2. **Load Workflows:**
   - Upload workflow JSON files
   - Use ComfyUI Manager to install custom nodes

3. **Generate Images:**
   - Configure your workflow
   - Queue prompts
   - Download results from output folder

---

## ğŸ“ Directory Structure

```
/workspace/
â”œâ”€â”€ ComfyUI/                    # Main ComfyUI installation
â”‚   â”œâ”€â”€ models/                 # AI models
â”‚   â”‚   â”œâ”€â”€ checkpoints/        # Base models (SDXL, Flux, etc.)
â”‚   â”‚   â”œâ”€â”€ vae/                # VAE models
â”‚   â”‚   â”œâ”€â”€ loras/              # LoRA models
â”‚   â”‚   â”œâ”€â”€ controlnet/         # ControlNet models
â”‚   â”‚   â”œâ”€â”€ upscale_models/     # Upscaler models
â”‚   â”‚   â”œâ”€â”€ clip/               # CLIP models
â”‚   â”‚   â””â”€â”€ unet/               # UNET models
â”‚   â”œâ”€â”€ custom_nodes/           # Custom nodes
â”‚   â”œâ”€â”€ output/                 # Generated images
â”‚   â””â”€â”€ input/                  # Input images
â”œâ”€â”€ scripts/                    # Setup scripts
â””â”€â”€ logs/                       # Log files
```

---

## ğŸš€ Advanced: Custom Model Downloads

Edit the model list in `scripts/download_models.py`:

```python
MODELS = {
    "checkpoints": [
        {
            "name": "your-model.safetensors",
            "url": "https://huggingface.co/...",
            "size": "6.5GB"
        }
    ]
}
```

Then run:
```bash
python3 /workspace/scripts/download_models.py
```

---

## ğŸ› Troubleshooting

### ComfyUI not starting?
```bash
# Check logs
tail -50 /workspace/comfyui.log

# Restart ComfyUI
pkill -f "python.*main.py"
cd /workspace/ComfyUI && python3 main.py --listen 0.0.0.0 --port 8188
```

### Models not downloading?
```bash
# Check download log
tail -50 /workspace/model_download.log

# Manually download models
cd /workspace
python3 scripts/download_models.py
```

### Out of disk space?
```bash
# Check disk usage
df -h /workspace

# Clean up old outputs
rm -rf /workspace/ComfyUI/output/*

# Remove temp files
find /tmp -type f -mtime +1 -delete
```

### CUDA errors?
```bash
# Check GPU
nvidia-smi

# Verify CUDA version
python3 -c "import torch; print(f'CUDA: {torch.version.cuda}')"

# Check PyTorch GPU support
python3 -c "import torch; print(f'GPU Available: {torch.cuda.is_available()}')"
```

---

## ğŸ’¡ Tips & Best Practices

- âœ… **Enable Container Caching** in Codex for faster restarts
- âœ… **Use Network Storage** for persistent model storage
- âœ… **Set HF_TOKEN** for accessing gated models (Flux, SDXL variants)
- âœ… **Monitor GPU usage** with `nvidia-smi` or `watch -n 1 nvidia-smi`
- âœ… **Save workflows** regularly (Download JSON from ComfyUI)
- âœ… **Use Jupyter** for batch processing and automation

---

## ğŸ”„ Updating ComfyUI

```bash
cd /workspace/ComfyUI
git pull
pip install -r requirements.txt
```

---

## ğŸ“š Resources

- **ComfyUI Docs:** https://github.com/comfyanonymous/ComfyUI
- **ComfyUI Manager:** https://github.com/ltdrdata/ComfyUI-Manager
- **Model Library:** See `comfyui_models_complete_library.md`
- **GPU Compatibility:** See `docs/gpu-compatibility.md`
- **Troubleshooting:** See `docs/troubleshooting.md`

---

## ğŸ†˜ Support

For issues or questions:
- Check logs: `/workspace/*.log`
- GitHub Issues: https://github.com/EcomTree/runpod-comfyui-cloud/issues
- RunPod Docs: https://docs.runpod.io/

---

**Created for Codex Environment** ğŸš€  
**Compatible with:** RunPod, Vast.ai, Lambda Labs, and other cloud GPU providers

