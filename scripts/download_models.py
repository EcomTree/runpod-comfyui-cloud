#!/usr/bin/env python3
"""
ComfyUI Model Downloader Script
L√§dt alle validierten ComfyUI Modelle in das angegebene Verzeichnis herunter.
"""

import os
import json
import requests
import time
import sys
import shutil
from pathlib import Path
from urllib.parse import urlparse
import subprocess

HF_TOKEN = os.getenv("HF_TOKEN")

SESSION = requests.Session()
SESSION.headers.update({
    'User-Agent': 'ComfyUI-Model-Downloader/1.0'
})

if HF_TOKEN:
    SESSION.headers['Authorization'] = f'Bearer {HF_TOKEN.strip()}'
else:
    print("‚ö†Ô∏è  Kein HF_TOKEN gesetzt. Gesch√ºtzte Hugging Face Downloads k√∂nnen fehlschlagen.")


class ComfyUIModelDownloader:
    def __init__(self, base_dir="/workspace", verification_file="link_verification_results.json"):
        self.base_dir = Path(base_dir)
        self.verification_file = verification_file
        self.models_dir = self.base_dir / "ComfyUI" / "models"
        self.session = SESSION

        # Erstelle Verzeichnisstruktur
        self.create_directory_structure()

    def create_directory_structure(self):
        """Erstellt die notwendige ComfyUI Verzeichnisstruktur."""
        directories = [
            "checkpoints",
            "unet",
            "vae",
            "clip",
            "t5",
            "clip_vision",
            "controlnet",
            "loras",
            "upscale_models",
            "diffusion_models",
            "animatediff_models",
            "text_encoders",
            "ipadapter"
        ]

        for dir_name in directories:
            (self.models_dir / dir_name).mkdir(parents=True, exist_ok=True)

        print(f"üìÅ Verzeichnisstruktur erstellt in: {self.models_dir}")

    def load_verified_links(self):
        """L√§dt die verifizierten Links aus der JSON-Datei."""
        try:
            with open(self.verification_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                return data.get('valid_links', [])
        except FileNotFoundError:
            print(f"‚ùå Verifikationsdatei {self.verification_file} nicht gefunden!")
            print("üîç F√ºhre zuerst 'python3 scripts/verify_links.py' aus.")
            sys.exit(1)

    def determine_target_directory(self, url):
        """Bestimmt das Zielverzeichnis basierend auf der URL und dem Dateinamen."""
        filename = Path(urlparse(url).path).name.lower()

        # Mapping von Dateiendungen zu Verzeichnissen
        mapping = {
            # Checkpoints (SD1.5, SDXL, etc.)
            'checkpoints': ['.ckpt', '.safetensors'],

            # FLUX und andere UNet Modelle
            'unet': ['flux', 'sd3', 'auraflow', 'hunyuan', 'kolors', 'lumina'],

            # VAE Modelle
            'vae': ['vae', 'kl-f8-anime'],

            # CLIP Encoder
            'clip': ['clip', 'open_clip'],

            # T5 Encoder
            't5': ['t5', 'umt5'],

            # CLIP Vision
            'clip_vision': ['clip_vision', 'image_encoder'],

            # ControlNet
            'controlnet': ['controlnet', 'control_', 'canny', 'depth', 'openpose', 'scribble'],

            # LoRAs
            'loras': ['lora', '.lora'],

            # Upscaler
            'upscale_models': ['esrgan', 'realesrgan', 'swinir', '4x', '2x', 'upscale'],

            # AnimateDiff
            'animatediff_models': ['animatediff', 'mm_', 'motion'],

            # IP-Adapter
            'ipadapter': ['ip-adapter', 'ip_adapter'],

            # Text Encoders (allgemein)
            'text_encoders': ['text_encoder', 'encoder']
        }

        for directory, patterns in mapping.items():
            # Check if filename contains patterns or has specific extensions
            for pattern in patterns:
                if pattern.startswith('.'):
                    if filename.endswith(pattern):
                        return directory
                elif pattern in filename:
                    return directory

        # Default fallback
        return "diffusion_models"

    def download_file(self, url, target_path, retry_count=3):
        """L√§dt eine einzelne Datei herunter mit Retry-Logik."""
        target_path = Path(target_path)
        target_path.parent.mkdir(parents=True, exist_ok=True)

        for attempt in range(retry_count):
            try:
                print(f"‚¨áÔ∏è  Lade herunter: {Path(url).name} (Versuch {attempt + 1}/{retry_count})")

                # Stream download f√ºr gro√üe Dateien
                with self.session.get(url, stream=True, timeout=30) as response:
                    response.raise_for_status()

                    # Hole Dateigr√∂√üe f√ºr Fortschrittsanzeige
                    total_size = int(response.headers.get('content-length', 0))

                    with open(target_path, 'wb') as f:
                        downloaded = 0
                        for chunk in response.iter_content(chunk_size=8192):
                            if chunk:
                                f.write(chunk)
                                downloaded += len(chunk)

                                # Fortschritt f√ºr gro√üe Dateien
                                if total_size > 0 and downloaded % (10 * 1024 * 1024) == 0:  # Alle 10MB
                                    progress = (downloaded / total_size) * 100
                                    print(f"   üìà {progress:.1f}% ({downloaded / 1024 / 1024:.1f} MB)")

                print(f"‚úÖ Erfolgreich heruntergeladen: {target_path}")
                return True

            except requests.exceptions.RequestException as e:
                print(f"‚ùå Fehler beim Download (Versuch {attempt + 1}): {e}")
                if attempt < retry_count - 1:
                    wait_time = (attempt + 1) * 5  # Exponentielles Backoff
                    print(f"‚è≥ Warte {wait_time} Sekunden vor erneutem Versuch...")
                    time.sleep(wait_time)
                else:
                    print(f"‚ùå Maximale Versuche erreicht f√ºr: {url}")
                    return False

            except Exception as e:
                print(f"‚ùå Unerwarteter Fehler: {e}")
                return False

    def download_all_models(self, parallel_downloads=3):
        """L√§dt alle Modelle herunter."""
        valid_links = self.load_verified_links()

        if not valid_links:
            print("‚ùå Keine validierten Links gefunden!")
            return

        print(f"üöÄ Starte Download von {len(valid_links)} Modellen...")
        print(f"üìÅ Zielverzeichnis: {self.models_dir}")
        print(f"‚ö° Parallele Downloads: {parallel_downloads}")

        successful = 0
        failed = 0

        # F√ºr einfachere parallele Downloads verwenden wir einen ThreadPool
        from concurrent.futures import ThreadPoolExecutor, as_completed

        def download_single_model(url):
            target_dir = self.determine_target_directory(url)
            target_path = self.models_dir / target_dir / Path(url).name

            # √úberspringe, wenn Datei bereits existiert
            if target_path.exists():
                print(f"‚è≠Ô∏è  √úberspringe (bereits vorhanden): {target_path.name}")
                return True

            return self.download_file(url, target_path)

        # F√ºhre Downloads sequentiell aus (stabiler f√ºr gro√üe Dateien)
        for i, url in enumerate(valid_links, 1):
            print(f"\nüì¶ [{i}/{len(valid_links)}] Verarbeite: {Path(url).name}")

            if download_single_model(url):
                successful += 1
            else:
                failed += 1

            # Kurze Pause zwischen Downloads
            time.sleep(1)

        print("\nüéâ Download-Statistik:")
        print(f"‚úÖ Erfolgreich: {successful}")
        print(f"‚ùå Fehlgeschlagen: {failed}")
        print(f"üìä Erfolgsrate: {(successful / (successful + failed)) * 100:.1f}%")

        if failed > 0:
            print(f"\n‚ö†Ô∏è  {failed} Downloads sind fehlgeschlagen.")
            print("üîÑ Du kannst das Script erneut ausf√ºhren, um fehlgeschlagene Downloads zu wiederholen.")
        else:
            print("\nüéä Alle Downloads erfolgreich abgeschlossen!")

    def create_download_summary(self):
        """Erstellt eine Zusammenfassung der heruntergeladenen Modelle."""
        summary_file = self.base_dir / "downloaded_models_summary.json"

        model_info = {}
        for root, dirs, files in os.walk(self.models_dir):
            for file in files:
                if file.endswith(('.safetensors', '.ckpt', '.pth', '.bin', '.pt')):
                    rel_path = os.path.relpath(root, self.models_dir)
                    category = rel_path if rel_path != '.' else 'root'

                    if category not in model_info:
                        model_info[category] = []

                    file_path = Path(root) / file
                    size_mb = file_path.stat().st_size / (1024 * 1024)

                    model_info[category].append({
                        'filename': file,
                        'size_mb': round(size_mb, 2),
                        'path': str(file_path.relative_to(self.base_dir))
                    })

        # Sortiere nach Kategorie und Dateiname
        for category in model_info:
            model_info[category].sort(key=lambda x: x['filename'])

        with open(summary_file, 'w', encoding='utf-8') as f:
            json.dump({
                'total_files': sum(len(files) for files in model_info.values()),
                'total_size_mb': round(sum(sum(f['size_mb'] for f in files) for files in model_info.values()), 2),
                'download_date': time.time(),
                'models': model_info
            }, f, indent=2, ensure_ascii=False)

        print(f"üìã Download-Zusammenfassung erstellt: {summary_file}")

        return summary_file

def main():
    """Hauptfunktion."""
    if len(sys.argv) > 1:
        base_dir = sys.argv[1]
    else:
        base_dir = "/workspace"

    print("ü§ñ ComfyUI Model Downloader")
    print("=" * 50)
    print(f"üìÅ Basisverzeichnis: {base_dir}")

    downloader = ComfyUIModelDownloader(base_dir)

    # Best√§tigung einholen
    print("\n‚ö†Ô∏è  ACHTUNG: Dies wird viele gro√üe Modelle herunterladen!")
    print("üíæ Stelle sicher, dass gen√ºgend Speicherplatz verf√ºgbar ist.")
    print("üåê Eine stabile Internetverbindung wird empfohlen.")

    try:
        input("\nüöÄ Dr√ºcke Enter um mit dem Download zu beginnen...")
    except KeyboardInterrupt:
        print("\n‚èπÔ∏è  Download abgebrochen.")
        sys.exit(0)

    # Start download
    start_time = time.time()
    downloader.download_all_models(parallel_downloads=1)  # Sequentiell f√ºr Stabilit√§t
    download_time = time.time() - start_time

    # Erstelle Zusammenfassung
    print("\nüìã Erstelle Download-Zusammenfassung...")
    summary_file = downloader.create_download_summary()

    print("\n‚è±Ô∏è  Download-Dauer:")
    print(f"   {download_time:.1f} Sekunden ({download_time/60:.1f} Minuten)")

    print("\n‚úÖ Download-Prozess abgeschlossen!")
    print(f"üìÑ Siehe {summary_file} f√ºr Details.")

if __name__ == "__main__":
    main()
